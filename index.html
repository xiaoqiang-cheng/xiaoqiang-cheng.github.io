<!DOCTYPE HTML>
<html lang="zh-CN"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>程晓强</title>

  <meta name="author" content="Xiaoqiang Cheng">
  <!--meta name="viewport" content="width=device-width, initial-scale=1"-->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=0" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel='shortcut icon' type='image/x-icon' href='logo.jpg' />
</head>

<body>
  <table style="width:100%;max-width:1200px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:15%;max-width:15%">
              <a href="images/Photo/my2.jpg" target="_blank"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Photo/my2.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:2.5%;width:63%;vertical-align:middle;line-height:20px">
              <p style="text-align:left">
                <name>Xiaoqiang Cheng | 程晓强</name>
              </p>
                我于2021年硕士毕业于天津大学，硕士阶段进行自动驾驶感知技术相关研究，主要针对基于LiDAR的目标检测和跟踪任务。毕业后我加入驭势科技（UISEE）成为一名自动驾驶感知算法工程师，并工作至今。因此，我具备多年的自动驾驶感知算法研究和落地经验。
              <p>
                </p>
                在学习和工作期间，在团队的共同努力下，我们参与了很多自动驾驶相关竞赛并获得不错的成绩，也曾经参与过一些顶会文章。
                <p>

                </p>
                你可以通过以下方式 了解 & 联系 我
              <p>



              </p>
              <p style="text-align:left">
                <a href="mailto: xiaoqiang.cheng@foxmail.com" target="_blank">Email</a> &nbsp/&nbsp
                <a href="data/CV/xiaoqiang.pdf" target="_blank">CV</a> &nbsp/&nbsp
                <a href="https://www.zhihu.com/people/cheng-xiao-21-61" target="_blank">知乎</a> &nbsp/&nbsp
                <a href="https://xiaoqiang-cheng.github.io/blog/" target="_blank">Blog</a> &nbsp/&nbsp
                <a href="https://github.com/xiaoqiang-cheng" target="_blank">Github</a>
              </p>
            </td>

          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle;line-height:20px">
              <heading>Summary</heading>
              <p>
                我从事自动驾驶行业感知技术相关工作。擅长基于深度学习2D & 3D目标检测、跟踪、分割等视觉任务。曾参与、设计并实现多种SOTA的视觉方法。曾多次参加自动驾驶挑战赛（实车&仿真竞赛）和相关视觉任务竞赛（like CVPR challenge），在团队协作下获得不错的成绩。
                此外，具备深度学习方法的落地部署经验，TensorRT加速SNPE量化等。熟悉NV平台的自定义算子实现，CUDA并行加速等。<br> <br>

                除自动驾驶技术外，我擅长UI编程，喜欢制作一些有趣的工具，例如 <a href="https://github.com/xiaoqiang-cheng/Oviz" target="_blank">Oviz (一个便捷的视觉任务可视化工具)</a>。 <br><br>

                我热爱技术，喜欢运动(打球，徒步)，希望做一些有趣和有影响力的事情。
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>相关研究</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <!--viewformer-->
            <tr onmouseout="j202301_stop()" onmouseover="j202301_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/Viewformer/viewformer.jpg" alt="clean-usnob" width="400" height="230">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2405.04299" target="_blank">
                <papertitle>ViewFormer: Exploring Spatiotemporal Modeling for Multi-View 3D Occupancy Perception via View-Guided Transformers</papertitle>
                </a>
                <br>
                <strong>Jinke Li<sup>&#8270</sup></strong>,
                ...,
                <strong>Xiaoqiang Cheng</strong>
                <br>
                <em>In European Conference on Computer Vision (ECCV) </em>, 2024
                <br>
                <a href="data/ViewFormer/viewformer.pdf" target="_blank">paper</a>
                <p>一种高效的基于时序特征的占用网络预测方法，我们提出了View-based att. 和更细粒度的OCC flow任务</p>
            </td>
            </tr>

            <!--phnet-->
            <tr onmouseout="j202301_stop()" onmouseover="j202301_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/Phnet/phnet.jpg" alt="clean-usnob" width="400" height="230">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2205.07002" target="_blank">
                <papertitle>Panoptic-PHNet: Towards Real-Time and High-Precision LiDAR Panoptic Segmentation via Clustering Pseudo Heatmap</papertitle>
                </a>
                <br>
                <strong>Jinke Li<sup>&#8270</sup></strong>,
                ...,
                <strong>Xiaoqiang Cheng</strong>
                <br>
                <em>In Computer Vision and Pattern Recognition (CVPR) </em>, 2022
                <br>
                <a href="data/Phnet/phnet.pdf" target="_blank">paper</a>
                <p>这是一个高精度且实时的点云全景分割网络，我们在nuscenes和KITTI数据集上取得了SOTA</p>
            </td>
            </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>专利与软著</heading>
              </td>
            </tr>
        </tbody></table>
        <ol>
            <li>程晓强,等. 目标匹配方法、装置、设备及存储介质[P]. 北京市：CN202111474736.9</li>
            <li>程晓强,等. 多目标匹配方法、装置、电子设备和存储介质[P]. 北京市：CN202211562631.3</li>
            <li>程晓强,等. 闸机开度检测方法、装置、设备、介质及车辆[P]. 北京市：CN202211184169.8</li>
            <li>程晓强,等. 目标检测方法、装置、电子设备和存储介质[P]. 北京市：CN202310583887.0</li>
            <li>程晓强,等. 非极大值抑制方法、装置、电子设备和存储介质[P]. 北京市：CN202311733978.4.</li>
            <li>程晓强,等. USEG点云语义分割标注系统[CP]. 北京市: 2024SR0534619</li>

        </ol>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>荣誉奖励</heading>
              </td>
            </tr>
        </tbody></table>
        <ol>
            <li>2024 ICRA RoboDrive Challenge Robust Occpancy Prediction 1st Place</li>
            <li>2021 NeurIPS Panoptic nuScenes challenge 1st Place</li>
            <li>2020 年第四届世界智能驾驶挑战赛决赛一等奖</li>
            <li>2017 年“瑞萨杯”全国大学生电子设计竞赛二等奖</li>
            <li>2016 年国际ICAN创新创业大赛全国二等奖</li>
            <li>2016 年河北省“TI杯”电子设计竞赛二等奖</li>
        </ol>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
                <p style="text-align:right;font-size:small;">
                  Copyright@Xiaoqiang Cheng 2024. Template is modified from <a href="https://github.com/jonbarron/jonbarron_website">Jonbarron</a>.
                </p>
              <br>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
